# =============================================================
# graph2.py â€” RAG Answer Graph (LangGraph)
# Sorgu â†’ retrieve (vektÃ¶r arama + re-rank) â†’ generate (LLM) â†’ evaluate (metrik)
# Retry kapÄ±sÄ± ile metrikler eÅŸik altÄ±ndaysa tekrar Ã¼ret.
# Bu dosya sadece Graphâ€‘2 (cevaplama) akÄ±ÅŸÄ±nÄ± iÃ§erir; ingest Graphâ€‘1â€™dedir.
# =============================================================
# Ortak tipler/objeler (Document, splitter vb.) ve yardÄ±mcÄ±lar burada toplanÄ±r
from imports import *
# Servis katmanÄ±: vektÃ¶r DB, reranker, RAG zinciri ve kalite ayarlarÄ±
from services import (
    TOP_K_INITIAL, TOP_R, RERANK_THRESHOLD,
    vectordb, reranker, get_rag_chain, llm_generate
)

# Tip ipuÃ§larÄ± ve LangGraph Ã§ekirdeÄŸi
from typing import List, Dict, Any, Tuple, TypedDict, Optional, Iterable
from langgraph.graph import StateGraph, END

# Graphâ€‘2â€™nin durum sÃ¶zlÃ¼ÄŸÃ¼ (state). AkÄ±ÅŸ boyunca bu anahtarlar gÃ¼ncellenir.
# - query: KullanÄ±cÄ± sorusu
# - doc_id: Hangi PDFâ€™e filtreleneceÄŸi (yoksa tÃ¼m koleksiyon)
# - retrieved: Ä°lk vektÃ¶r arama dÃ¶nÃ¼ÅŸÃ¼ (Document listesi)
# - reranked: (Document, skor) listesi (CrossEncoder sonrasÄ±)
# - top_docs: LLMâ€™e gidecek (en iyi N) konteks parÃ§alarÄ±
# - answer: LLM cevabÄ± (model tarafÄ±ndan Ã¼retilen metin)
# - metrics: Ã–lÃ§Ã¼m skorlarÄ± (0..1)
# - attempt/max_retries/threshold: Retry kontrol parametreleri
class G2State(TypedDict, total=False):
    query: str
    doc_id: Optional[str]
    doc_ids: Optional[List[str]]
    model_name: Optional[str]
    retrieved: List[Document]
    reranked: List[Tuple[Document, float]]
    top_docs: List[Tuple[Document, float]]
    answer: str
    metrics: Dict[str, float]
    attempt: int
    max_retries: int
    threshold: float
    trace: List[str]

# En iyi N dokÃ¼manÄ± tek bir CONTEXT metnine Ã§evir (LLMâ€™e verilecek gÃ¶vde)
def _build_context_string(docs: List[Tuple[Document, float]]) -> str:
    return "\n\n---\n\n".join([doc.page_content for doc, _ in docs])


# Basit lexical benzerlik (fallback olarak kullanÄ±lÄ±r)
def _jaccard(a: str, b: str) -> float:
    sa, sb = set(a.lower().split()), set(b.lower().split())
    return (len(sa & sb) / len(sa | sb)) if sa and sb else 0.0

# Semantic kÄ±yas iÃ§in BERTScore; offline ortamda import baÅŸarÄ±sÄ±z olabilir â†’ fallback
try:
    from bert_score import score as _bert_score
except Exception:
    _bert_score = None

# Cevaptan "Sources/Kaynaklar" bÃ¶lÃ¼mÃ¼nÃ¼ ayÄ±kla; sadece gerÃ§ek yanÄ±tÄ± Ã¶lÃ§elim
def _extract_pure_answer(text: str) -> str:
    if not text:
        return ""
    cuts = [
        "ğŸ”— Sources", "Sources / Metadata", "Kaynaklar", "Kaynak alÄ±ntÄ±larÄ±",
        "Sources:", "Metadata:", "References"
    ]
    for c in cuts:
        idx = text.find(c)
        if idx != -1:
            return text[:idx].strip()
    return text.strip()

# Reâ€‘rank sonrasÄ± topâ€‘k konteksi kÄ±sa bir metin olarak derle (gÃ¼rÃ¼ltÃ¼yÃ¼ azaltÄ±r)
def _top_context_text_from_top_docs(state: G2State, k: int = 5) -> str:
    top_docs = state.get("top_docs") or []
    if top_docs and isinstance(top_docs[0], tuple):
        docs_only = [d for d, _ in top_docs[:k]]
    else:
        docs_only = top_docs[:k]
    return "\n\n---\n\n".join([d.page_content for d in docs_only]) if docs_only else ""

# BERTScore yoksa Jaccardâ€™a dÃ¼ÅŸen gÃ¼venli semantic skorlayÄ±cÄ±
def _safe_bertscore(a: str, b: str) -> float:
    """Return a semantic similarity in [0,1]; falls back to Jaccard if offline."""
    if _bert_score is None:
        return _jaccard(a, b)
    try:
        _, _, f1 = _bert_score([a], [b], lang="en", verbose=False)
        val = float(f1[0])
        return max(0.0, min(1.0, val))
    except Exception:
        return _jaccard(a, b)

# 1) RETRIEVE â€” VektÃ¶r arama + CrossEncoder reâ€‘rank
# - doc_id varsa sadece ilgili PDFâ€™te ara
# - Ä°lk adaylarÄ± k=TOP_K_INITIAL ile getir, CE ile sÄ±rala
# - EÅŸik altÄ±nÄ± at, TOP_R kadarÄ±nÄ± LLM iÃ§in hazÄ±rla
def retrieve_node(state: G2State) -> G2State:
    state.setdefault("trace", []).append("retrieve")
    # PaylaÅŸÄ±lan Chroma istemcisini al
    db = vectordb()
    # Ä°steÄŸe baÄŸlÄ± filtre: tek veya Ã§oklu dokÃ¼man
    _doc_ids = state.get("doc_ids")
    _doc_id  = state.get("doc_id")
    if _doc_ids:
        filt = {"doc_id": {"$in": _doc_ids}}
    elif _doc_id:
        filt = {"doc_id": _doc_id}
    else:
        filt = None
    # Ä°lk vektÃ¶r arama (embedding uzayÄ±nda en yakÄ±n k aday)
    retrieved: List[Document] = db.similarity_search(state["query"], k=TOP_K_INITIAL, filter=filt)

    # Reâ€‘rank iÃ§in (soru, aday_parÃ§a) Ã§iftlerini hazÄ±rla
    pairs = [(state["query"], d.page_content) for d in retrieved]
    # CrossEncoder puanlarÄ± (daha ince ayrÄ±m)
    if pairs:
        scores = reranker().predict(pairs)
        # YÃ¼ksekten dÃ¼ÅŸÃ¼ÄŸe sÄ±rala
        ranked = sorted(zip(retrieved, list(scores)), key=lambda x: x[1], reverse=True)
    else:
        ranked = []

    # DÃ¼ÅŸÃ¼k skorlularÄ± ele (eÅŸik)
    filtered = [(d, s) for d, s in ranked if s >= RERANK_THRESHOLD]
    # LLMâ€™e gidecek en iyi N parÃ§a
    top_docs = filtered[:TOP_R] if len(filtered) >= TOP_R else ranked[:TOP_R]

    # Durumu gÃ¼ncelle
    state["retrieved"] = retrieved
    state["reranked"] = ranked
    state["top_docs"] = top_docs
    return state


# 2) GENERATE â€” RAG zinciri ile LLM cevabÄ± Ã¼ret
# - Context boÅŸsa "I don't know." dÃ¶n
# - Aksi halde prompt â†’ LLM â†’ metin akÄ±ÅŸÄ±
def generate_node(state: G2State) -> G2State:
    state.setdefault("trace", []).append("generate")
    # Prompt + LLM + parser zinciri
    rag = get_rag_chain(model_name=state.get("model_name"))
    # SeÃ§ilen top parÃ§alarÄ± tek bir CONTEXTâ€™e Ã§evir
    context = _build_context_string(state.get("top_docs", []))
    # Konteks yoksa modelden cevap isteme
    if not context.strip():
        state["answer"] = "I don't know."
        return state

    # LLMâ€™den cevabÄ± iste ve sadece dÃ¼z metni sakla
    result = rag.invoke({"context": context, "question": state["query"]})
    state["answer"] = result.content if hasattr(result, "content") else (result if isinstance(result, str) else str(result))
    return state


# 3) EVALUATE â€” Metrikler (semanticâ€‘first)
# - groundedness: answer â†” context
# - context_relevance: question â†” context
# - answer_relevance: answer â†” question
# Not: Metadata/kaynak listesi Ã¶lÃ§Ã¼me dahil edilmez (pure answer)
def evaluate_node(state: G2State) -> G2State:
    state.setdefault("trace", []).append("evaluate")
    # GÃ¼rÃ¼ltÃ¼yÃ¼ azalt: topâ€‘k kÄ±sa konteks derle
    context_compact = _top_context_text_from_top_docs(state, k=5)
    # Fallback: elimizdeki top_docs metni
    if not context_compact:
        context_compact = _build_context_string(state.get("top_docs", []))

    # Sadece gerÃ§ek yanÄ±tÄ± Ã¶lÃ§ (kaynak/metadata hariÃ§)
    answer = _extract_pure_answer(state.get("answer", ""))
    question = state.get("query", "")

    # Semantic groundedness (BERTScore varsa)
    grounded_sem = _safe_bertscore(answer, context_compact)
    # Soru â†” konteks uyumu
    context_rel  = _safe_bertscore(question, context_compact)
    # Cevap â†” soru uyumu
    answer_rel   = _safe_bertscore(answer, question)

    # Lexical bonus: en iyi Jaccard eÅŸleÅŸmesini ekle (kÃ¼Ã§Ã¼k aÄŸÄ±rlÄ±kla)
    ctx = state.get("top_docs", [])
    j_best = max((_jaccard(answer, d.page_content) for d, _ in ctx), default=0.0)
    grounded = 0.8 * grounded_sem + 0.2 * j_best

    # Yuvarla ve [0,1] aralÄ±ÄŸÄ±nda tut
    def _rc(x: float) -> float:
        return max(0.0, min(1.0, round(float(x), 3)))

    # Metrikleri stateâ€™e yaz
    state["metrics"] = {
        "context_relevance": _rc(context_rel),
        "answer_relevance": _rc(answer_rel),
        "groundedness": _rc(grounded),
    }
    return state

# Retry kapÄ±sÄ± â€” tÃ¼m metrikler eÅŸik Ã¼stÃ¼ndeyse bitir; deÄŸilse ve deneme hakkÄ± varsa tekrar Ã¼ret
def should_retry(state: G2State) -> str:
    th = state.get("threshold", 0.7)
    mets = state.get("metrics", {})
    ok = all(v >= th for v in mets.values())
    if ok:
        return "finish"
    if state.get("attempt", 0) >= state.get("max_retries", 1):
        return "finish"
    return "retry"


# Bir sonraki deneme iÃ§in attempt sayacÄ±nÄ± artÄ±r
def retry_gate(state: G2State) -> G2State:
    state.setdefault("trace", []).append("retry_gate")
    state["attempt"] = state.get("attempt", 0) + 1
    return state

# Graph tanÄ±mÄ± â€” dÃ¼ÄŸÃ¼mleri ekle, kenarlarÄ± Ã§iz, koÅŸullu geÃ§iÅŸleri baÄŸla ve derle
def build_graph2():
    # Tip gÃ¼venli state ile bir grafik oluÅŸtur
    g = StateGraph(G2State)
    
    g.add_node("retrieve", retrieve_node)
    
    g.add_node("generate", generate_node)
    
    g.add_node("evaluate", evaluate_node)
    
    g.add_node("retry_gate", retry_gate)

    # GiriÅŸ dÃ¼ÄŸÃ¼mÃ¼
    g.set_entry_point("retrieve")
    # AkÄ±ÅŸ baÄŸlantÄ±larÄ±
    g.add_edge("retrieve", "generate")
    g.add_edge("generate", "evaluate")

    g.add_conditional_edges(
        "evaluate",
        should_retry,
        {
            "retry": "retry_gate",
            "finish": END,
        },
    )
    g.add_edge("retry_gate", "generate")
    # Ã‡alÄ±ÅŸtÄ±rÄ±labilir hÃ¢le getir
    return g.compile()


# VarsayÄ±lan metrik eÅŸiÄŸi (retry mekanizmasÄ± iÃ§in)
DEFAULT_THRESHOLD = 0.7

# DÄ±ÅŸarÄ±dan Ã§aÄŸrÄ±lan yardÄ±mcÄ±: grafiÄŸi kur, input state ver, sonucu UI iÃ§in paketle
def run_graph2(query: str, doc_id: Optional[str] = None, doc_ids: Optional[List[str]] = None, max_retries: int = 2, threshold: float = DEFAULT_THRESHOLD, model_name: Optional[str] = None) -> Dict[str, Any]:
    # GrafiÄŸi derle
    app = build_graph2()
    # BaÅŸlangÄ±Ã§ stateâ€™i ile grafiÄŸi Ã§alÄ±ÅŸtÄ±r
    state: G2State = app.invoke({
        "query": query,
        "doc_id": doc_id,
        "doc_ids": doc_ids,
        "attempt": 0,
        "max_retries": max_retries,
        "threshold": threshold,
        "model_name": model_name,
    })

    # UI dostu kaynak listesi hazÄ±rla (sayfa, skor, snippet)
    sources: List[Dict[str, Any]] = []
    # Top_docs iÃ§inden metadataâ€™yÄ± Ã§Ä±kar ve zenginleÅŸtir
    for d, score in (state.get("top_docs") or []):
        meta = d.metadata or {}
        sources.append({
            "doc_id": meta.get("doc_id"),
            "chunk_id": meta.get("chunk_id"),
            "page": meta.get("page"),
            "source": meta.get("source"),
            "section": meta.get("section"),
            "title": meta.get("title"),
            "rerank_score": float(score),
            "snippet": d.page_content[:250],
        })

    # Cevap + metrikler + kaynaklar paketini dÃ¶ndÃ¼r
    return {
        "answer": state.get("answer", "I don't know."),
        "metrics": state.get("metrics", {}),
        "sources": sources,
        "trace": state.get("trace", []),
    }


# -------------------------------------------------------------
# Streaming execution for Graph-2
# Emits step names as they execute so the UI can update a single line
# Steps: retrieve -> generate -> evaluate -> (retry_gate -> generate -> evaluate)* -> done

def run_graph2_stream(
    query: str,
    doc_id: Optional[str] = None,
    doc_ids: Optional[List[str]] = None,
    max_retries: int = 2,
    threshold: float = DEFAULT_THRESHOLD,
    model_name: Optional[str] = None,
) -> Iterable[Tuple[str, Dict[str, Any]]]:
    """Yield (step_name, payload) as Graph-2 advances.

    Yields:
      ("retrieve", {})
      ("generate", {})
      ("evaluate", {"metrics": {...}})
      ("retry_gate", {"attempt": int})  # if retry triggered
      ...
      ("done", {"result": {...}})
    """
    # Initial state
    state: G2State = {
        "query": query,
        "doc_id": doc_id,
        "doc_ids": doc_ids,
        "attempt": 0,
        "max_retries": max_retries,
        "threshold": threshold,
        "model_name": model_name,
        "trace": [],
    }

    # 1) RETRIEVE
    yield ("retrieve", {})
    state = retrieve_node(state)

    # Loop: GENERATE -> EVALUATE (-> RETRY?)
    while True:
        # 2) GENERATE
        yield ("generate", {})
        state = generate_node(state)

        # 3) EVALUATE
        state = evaluate_node(state)
        yield ("evaluate", {"metrics": state.get("metrics", {})})

        # Decide
        decision = should_retry(state)
        if decision == "finish":
            break
        # else retry
        yield ("retry_gate", {"attempt": state.get("attempt", 0) + 1})
        state = retry_gate(state)
        # (loop continues with generate again)

    # Prepare UI-friendly sources
    sources: List[Dict[str, Any]] = []
    for d, score in (state.get("top_docs") or []):
        meta = d.metadata or {}
        sources.append({
            "doc_id": meta.get("doc_id"),
            "chunk_id": meta.get("chunk_id"),
            "page": meta.get("page"),
            "source": meta.get("source"),
            "section": meta.get("section"),
            "title": meta.get("title"),
            "rerank_score": float(score),
            "snippet": d.page_content[:250],
        })

    result = {
        "answer": state.get("answer", "I don't know."),
        "metrics": state.get("metrics", {}),
        "sources": sources,
        "trace": state.get("trace", []),
    }

    yield ("done", {"result": result})

# HÄ±zlÄ± yerel test (bu dosyayÄ± doÄŸrudan Ã§alÄ±ÅŸtÄ±rÄ±rsan)
if __name__ == "__main__":
    # Ã–rnek bir Ã§aÄŸrÄ± (doc_id verilmeden)
    out = run_graph2("Belgenin ana bulgularÄ± nelerdir?", doc_id=None)
    # Konsola yazdÄ±r
    print("\nAnswer:\n", out["answer"]) 
    print("Metrics:", out["metrics"]) 
    print("Sources:", [(s["page"], round(s["rerank_score"], 3)) for s in out["sources"]])